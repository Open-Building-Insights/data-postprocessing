{"cells":[{"cell_type":"markdown","metadata":{},"source":["## ingest_energy_estimations_Kenya\n","### Ingesting energy estimates into the database based on the building matching created by building_matching"]},{"cell_type":"markdown","metadata":{},"source":["### Initial configuration\n","#### To start working with this particular notebook, you need to provide necessary credential and settings\n","#### Below is an template of configuration, which is necessary prepare aside of this notebook and copy & paste all content in triple quotes to the next cell's input field\n","    \"\"\"\n","    {\n","    \"COS_ENDPOINT_URL\": \"s3.private.eu-de.cloud-object-storage.appdomain.cloud\",\n","    \"COS_AUTH_ENDPOINT_URL\": \"https://iam.cloud.ibm.com/oidc/token\",\n","    \"COS_APIKEY\": \"xxx\",\n","    \"DB2_CONNECTION_STRING\": \"jdbc:db2://65beb513-5d3d-4101-9001-f42e9dc954b3.brt9d04f0cmqeb8u7740.databases.appdomain.cloud:30371/BLUDB:sslConnection=true;useJDBC4ColumnNameAndLabelSemantics=false;db2.jcc.charsetDecoderEncoder=3;\",\n","    \"DB2_USERNAME\": \"xxx\",\n","    \"DB2_PASSWORD\": \"xxx\",\n","    \"UTILS_BUCKET\": \"notebook-utils-bucket\",\n","    \"ENERGY_ESTIMATION_BUCKET\": \"kenya-energy-estimation-matching\",\n","    \"JOB_STATUS_BUCKET\": \"notebook-job-status\",\n","    \"COUNTRY_TABLE\": \"FEATURES_DB_VIDA_EXTENDED\"\n","    }\n","    \"\"\"\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Read notebook configuration\n","import getpass\n","import json\n","\n","config_str = getpass.getpass('Enter your prepared config: ')\n","config = json.loads(config_str)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# import necessary libraries\n","import ibm_boto3\n","from botocore.client import Config\n","import pandas as pd\n","import geopandas as gpd\n","from tqdm import tqdm\n","import os\n","import sys\n","import traceback\n","import io\n","\n","import jaydebeapi as jdbc\n","import jpype\n","import threading\n","import time"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# cloud object storage client instance\n","cos_client = ibm_boto3.client(service_name='s3',\n","                              ibm_api_key_id=config[\"COS_APIKEY\"],\n","                              ibm_auth_endpoint=config[\"COS_AUTH_ENDPOINT_URL\"],\n","                              config=Config(signature_version='oauth'),\n","                              endpoint_url=config[\"COS_ENDPOINT_URL\"])\n","\n","response = cos_client.list_objects_v2(Bucket=config[\"UTILS_BUCKET\"])\n","\n","# download utils module\n","try:\n","    from utils import *\n","    print('External utils succesfully imported')\n","    \n","except Exception as e:\n","    print('Desired packages is missing in local env, downloading it...', e)\n","    for obj in response['Contents']:\n","        name = obj['Key']\n","        \n","        if name == 'db2jcc4.jar':\n","            streaming_body_1 = cos_client.get_object(Bucket=config[\"UTILS_BUCKET\"], Key=name)['Body']\n","            print(\"Downloading to localStorage :  \" + name)\n","            with io.FileIO(name, 'w') as file:\n","                for i in io.BytesIO(streaming_body_1.read()):\n","                    file.write(i)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def connect_to_db():\n","    '''\n","        Connect to the IBM DB2 database\n","    '''\n","    \n","    jar = 'db2jcc4.jar'\n","    os.environ['CLASSPATH'] = jar\n","\n","    args='-Djava.class.path=%s' % jar\n","    jvm_path = jpype.getDefaultJVMPath()\n","    try:\n","        jpype.startJVM(jvm_path, args)\n","    except Exception as e:\n","        print('startJVM exception: ', e)\n","        \n","    if jpype.isJVMStarted() and not jpype.isThreadAttachedToJVM():\n","        jpype.attachThreadToJVM()\n","        jpype.java.lang.Thread.currentThread().setContextClassLoader(jpype.java.lang.ClassLoader.getSystemClassLoader())\n","        \n","    \n","    conn = jdbc.connect(\n","                'com.ibm.db2.jcc.DB2Driver',\n","                config['DB2_CONNECTION_STRING'],\n","                [config[\"DB2_USERNAME\"], config[\"DB2_PASSWORD\"]],\n","                'db2jcc4.jar')\n","\n","    return conn\n","\n","conn = connect_to_db()\n","cursor = conn.cursor()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# check if exists matched parquets folder\n","parquets_folder = 'matched_buildings'\n","\n","if os.path.exists(parquets_folder) == False:\n","    os.mkdir(parquets_folder)\n","\n","files = os.listdir(parquets_folder)\n","\n","# list matched parquets from bucket \n","response = cos_client.list_objects_v2(Bucket=config[\"ENERGY_ESTIMATION_BUCKET\"])\n","objects = [i['Key'] for i in response['Contents']]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# select patquets that need to be downloaded\n","objects_to_download = [i for i in objects if i not in files]\n","objects_to_download"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# download remaining objects to the folder\n","for o in tqdm(objects_to_download, desc='Downloading', total=len(objects_to_download)):\n","    cos_client.download_file(config[\"ENERGY_ESTIMATION_BUCKET\"], o, os.path.join(parquets_folder, o))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def log_state_to_bucket(processing_state: dict):\n","    '''\n","        Function for updating matching state to the 'notebook-job-status' bucket\n","        Each call of this function uploads a selected json file with updated state to the afore mentioned bucket\n","    '''\n","    \n","    filename = f'ingesting energy_estimates_Kenya_status.json'\n","    with open(filename, \"w\") as outfile:\n","                json.dump(processing_state, outfile)\n","                \n","    cos_client.upload_file(\n","        Filename=filename,\n","        Bucket=config[\"JOB_STATUS_BUCKET\"],\n","        Key=filename,\n","        )"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["files = os.listdir(parquets_folder)\n","print(f'Amount of datasets in {parquets_folder} directory is: {len(files)}')\n","\n","# files.remove(files[0])\n","\n","files = [[i, os.path.getsize(os.path.join(parquets_folder, i)) / 1024**2] for i in files]\n","files.sort(key=lambda x: x[1])\n","\n","threads_amount = 4\n","\n","if len(files) % threads_amount == 0:\n","    files_in_batch = len(files) // threads_amount\n","else:\n","    files_in_batch = len(files) // threads_amount + 1\n","\n","    \n","thread_dfs = {thread_idx: [] for thread_idx in range(threads_amount)}\n","\n","current_thread_id = 0\n","\n","for file_idx in range(0, len(files), threads_amount):\n","    \n","    if current_thread_id == threads_amount:\n","        current_thread_id = 0\n","        \n","    thread_dfs[current_thread_id] += files[file_idx: file_idx + threads_amount]\n","    current_thread_id += 1\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["files"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["sum([i[1] for i in thread_dfs[0]])\n","\n","a = {}\n","\n","all_parquets = []\n","\n","for idx, j in thread_dfs.items():\n","    a[idx] = sum([i[1] for i in j])\n","    \n","#     parquets = [i[1] for i in j]\n","    all_parquets += [i[0] for i in j]\n","a"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["all_files = [i[0] for i in files]\n","all_files.sort()\n","all_parquets.sort()\n","all_parquets == all_files"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# overlap check\n","\n","for f in files:\n","    if f[0] not in all_parquets:\n","        print(f)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def update_DB2_row(cursor, row: dict):\n","    '''\n","    row: dict = {\n","                \"LATITUDE\": \"\",\n","                \"LONGITUDE\": \"\",\n","                \"ELEC_ACCESS_PERCENT\": \"\",\n","                \"ELEC_CONSUMPTION_KWH_MONTH\": \"\",\n","                \"ELEC_CONSUMPTION_STD_KWH_MONTH\": \"\"\n","                }\n","    '''\n","    \n","    sql = f\"\"\"\n","        UPDATE \"USER1\".\"{config[\"COUNTRY_TABLE\"]}\"\n","            SET\n","              \"ELEC_ACCESS_PERCENT\" = '{row['ELEC_ACCESS_PERCENT']}',     \n","              \"ELEC_CONSUMPTION_KWH_MONTH\" = '{row['ELEC_CONSUMPTION_KWH_MONTH']}',\n","              \"ELEC_CONSUMPTION_STD_KWH_MONTH\" = '{row['ELEC_CONSUMPTION_STD_KWH_MONTH']}'\n","            WHERE \n","                (LATITUDE = {row['LATITUDE']}) AND \n","                (LONGITUDE = {row['LONGITUDE']})\n","        \"\"\"\n","    \n","    cursor.execute(sql)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def process_thread_dataframes(df_names, start_from, processing_state, cursor, thread_id):\n","    \n","    print(f'Starting thread_id: {thread_id}')\n","    time.sleep(thread_id+1)\n","\n","    updated_buildings_in_thread = 0\n","    \n","    for df_idx, df_name in enumerate(df_names):\n","        \n","        if df_idx >= start_from:\n","            \n","            print(f'thread_id: {thread_id} processing df: {df_idx}')\n","            time.sleep(thread_id+1)\n","\n","            df = pd.read_parquet(os.path.join(parquets_folder, df_name))\n","            df = df.rename(\n","                    columns={\n","                        'elec access (%)': 'elec_access',\n","                        'cons (kWh/month)': 'elec_cons',\n","                        'std cons (kWh/month)': 'elec_std_cons',\n","                    })\n","\n","\n","            for row in df.itertuples():\n","\n","                item = {\n","                        \"LATITUDE\": row.latitude,\n","                        \"LONGITUDE\": row.longitude,\n","                        \"ELEC_ACCESS_PERCENT\": round(row.elec_access, 5),\n","                        \"ELEC_CONSUMPTION_KWH_MONTH\": round(row.elec_cons, 5),\n","                        \"ELEC_CONSUMPTION_STD_KWH_MONTH\": round(row.elec_std_cons, 5),\n","                        }\n","\n","                try:\n","\n","                    update_DB2_row(cursor, item)\n","                    updated_buildings_in_thread += 1\n","\n","                except Exception as e:\n","                    print(f'Thread id {thread_id} exception occured: {e}')\n","                    print(traceback.format_exc())\n","                    cursor = conn.cursor()\n","\n","                    update_DB2_row(cursor, item)\n","                    updated_buildings_in_thread += 1\n","\n","\n","            processing_state[f'processed_dfs_in_thread_{thread_id}'] = f'Processed {df_idx + 1} of {len(df_names)} | {round(100*(df_idx + 1)/len(df_names), 2)}% | Updated: {updated_buildings_in_thread}'\n","            if thread_id == 0:\n","\n","                try:\n","                    time.sleep(1)\n","                    log_state_to_bucket(processing_state)\n","                except Exception as le:\n","                    print(le)\n","            \n","            \n","    processing_state[f'processed_dfs_in_thread_{thread_id}'] = f'Processed {df_idx + 1} of {len(df_names)} | {round(100*(df_idx + 1)/len(df_names), 2)}% | Updated: {updated_buildings_in_thread} | THREAD FINISHED'\n","        \n","    try:\n","        log_state_to_bucket(processing_state)\n","    except Exception as le:\n","        print(le)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","processing_state = {}\n","\n","threads = []\n","\n","start_dfs = [\n","    0, # 0 thread\n","    0, # 1 thread\n","    0, # 2 thread\n","    0  # 3 thread\n","]\n","\n","for start_df_id, (thread_id, df_names) in zip(start_dfs, thread_dfs.items()):\n","    \n","    df_names = [i[0] for i in df_names]\n","    \n","    thread = threading.Thread(target=process_thread_dataframes, args=(df_names, start_df_id, processing_state, cursor, thread_id, ))\n","    threads.append(thread)\n","    \n","for thread in threads:\n","    thread.start()\n","    \n","for thread in threads:\n","    thread.join()"]}],"metadata":{"kernelspec":{"display_name":"Python 3.10","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":2}
